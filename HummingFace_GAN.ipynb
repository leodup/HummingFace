{"cells":[{"cell_type":"markdown","metadata":{"id":"LtILdAZxerIy"},"source":["#Project: HummingFace | GAN\n","\n","Léo Dupire & Mateus Aragão"]},{"cell_type":"markdown","metadata":{"id":"DQBMtGQSd2wk"},"source":["##Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B4nPzP7aMDdO","outputId":"3e6c9a0f-ef15-4b0e-dfeb-03c1a0073546"},"outputs":[{"name":"stdout","output_type":"stream","text":["/Users/leodupire/Desktop/HummingFace\n"]}],"source":["%cd ./Desktop/HummingFace"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"JCTC3B9DyCiU"},"outputs":[],"source":["#@title Imports\n","import os\n","import math\n","import numpy as np\n","from numpy.random import randn\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from scipy import signal\n","from scipy.io import wavfile\n","from pydub import AudioSegment\n","from IPython.display import Audio, display"]},{"cell_type":"markdown","metadata":{"id":"GO21c_FegAnt"},"source":["###Spectrogram Functions (explore MFCCs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g9XE66yPzyen"},"outputs":[],"source":["# Convert raw audio into spectrogram\n","def spectrogramify(instance, phase, nperseg=1000):\n","  # instance: record name\n","  # phase: train, val, or test\n","  dir = \"./nsynth-\" + str(phase) + \"/audio/\" + str(instance) + \".wav\"\n","  sample_rate, samples = wavfile.read(dir)\n","  frequencies, times, spectrogram = signal.stft(samples, fs=sample_rate, nperseg=nperseg)\n","\n","  return sample_rate, frequencies, times, spectrogram\n","\n","\n","# Display spectrogram\n","def show_spectro(times, frequencies, spectrogram):\n","  f = plt.figure()\n","  f.set_figwidth(5)\n","  f.set_figheight(3)\n","\n","  plt.pcolormesh(times, frequencies, np.abs(spectrogram))\n","  plt.ylabel('Frequency [Hz]')\n","  plt.xlabel('Time [sec]')\n","  plt.ylim([0, 2000])\n","  plt.show()\n","\n","\n","# Generate .wav file from spectrogram\n","def spectro_to_wav(spectrogram, sample_rate = 16000):\n","  _, gen = signal.istft(spectrogram, sample_rate)\n","  wavfile.write(\"output.wav\", sample_rate, gen.astype(np.int16))\n","  return True\n","\n","\n","# Display/play audio from .wav file\n","def spectro_to_audio(spectrogram, sample_rate = 16000):\n","  spectro_to_wav(spectrogram, sample_rate)\n","  wav = \"output.wav\"\n","  display(Audio(wav, autoplay=True))\n","\n","\n","# Convert imaginary-valued spectrogram into depth-2 matrix (depth #1: real, depth #2: imaginary)\n","def decompose_spect(y):\n","  y_real = []\n","  y_imag = []\n","  for i in range(len(y)):\n","    y_real.append(y[i].real)\n","    y_imag.append(y[i].imag)\n","  return np.array(y_real), np.array(y_imag)\n","\n","\n","# Convert depth-2 (real, imaginary) matrix back to depth-1 matrix with values = real + imaginary*i (i = sqrt(-1))\n","def recompose_spect(y_real, y_imag):\n","  y = 1j*y_imag\n","  y += y_real\n","  return np.array(y)"]},{"cell_type":"markdown","metadata":{"id":"YReaqXuBkl2L"},"source":["###Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample_rate = 16000\n","times = np.linspace(0, 1, 128)\n","freqs = np.linspace(0, 2032, 128)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_AUQCOkT7lwN"},"outputs":[],"source":["train_real = np.load(\"./train_real.npy\")\n","train_imag = np.load(\"./train_imag.npy\")\n","X = pd.read_csv(\"./train_df.csv\")\n","\n","test_real = np.load(\"./test_real.npy\")\n","test_imag = np.load(\"./test_imag.npy\")\n","test_X = pd.read_csv(\"./test_df.csv\")"]},{"cell_type":"markdown","metadata":{"id":"iC5pMj03Q7Z7"},"source":["##GAN"]},{"cell_type":"markdown","metadata":{"id":"yAY2FkigK58q"},"source":["This GAN did not perform well. It outputs noise, much like the Conditional GAN."]},{"cell_type":"markdown","metadata":{"id":"7ItBL-XGSC3c"},"source":["https://machinelearningmastery.com/upsampling-and-transpose-convolution-layers-for-generative-adversarial-networks/"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"PdGr1YRHRAZO"},"outputs":[],"source":["#@title Imports\n","import tensorflow as tf\n","# from tensorflow.keras import datasets, layers, models\n","from keras.models import Sequential\n","from keras.layers import Dense, Reshape, UpSampling2D, Conv2D, Conv2DTranspose, LeakyReLU, Flatten, Dropout\n","from keras import Input, Model, metrics, optimizers\n","from keras.utils.vis_utils import plot_model\n","from keras.optimizers import Adam\n","from keras.models import load_model"]},{"cell_type":"markdown","metadata":{"id":"h82LxuVi1jJ8"},"source":["###Build & Compile Model"]},{"cell_type":"markdown","metadata":{"id":"505J8dtadK1T"},"source":["####Discriminator\n","\n","https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2aDHS9kNdNKz"},"outputs":[],"source":["# define the standalone discriminator model\n","def define_discriminator(in_shape=(501,129,2)):\n","\tmodel = Sequential()\n","\tmodel.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\tmodel.add(Dropout(0.4))\n","\tmodel.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\tmodel.add(Dropout(0.4))\n","\tmodel.add(Flatten())\n","\tmodel.add(Dense(1, activation='sigmoid'))\n","\t# compile model\n","\topt = Adam(lr=0.0002, beta_1=0.5)\n","\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\treturn model\n"," \n","# define model\n","model = define_discriminator()\n","# summarize the model\n","model.summary()\n","# plot the model\n","plot_model(model, to_file='discriminator_plot.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z-EjztVimJ1t"},"outputs":[],"source":["# select real samples\n","def generate_real_samples(dataset, n_samples):\n","  # choose random instances\n","  ix = np.random.randint(0, dataset.shape[0], n_samples)\n","  # retrieve selected images\n","  X = dataset[ix]\n","  # generate 'real' class labels (1)\n","  y = np.ones((n_samples, 1))\n","  return X, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ky3s2ZBdmtll"},"outputs":[],"source":["# use the generator to generate n fake examples, with class labels\n","def generate_fake_samples(g_model, latent_dim, n_samples):\n","\t# generate points in latent space\n","\tx_input = generate_latent_points(latent_dim, n_samples)\n","\t# predict outputs\n","\tX = g_model.predict(x_input)\n","\t# create 'fake' class labels (0)\n","\ty = np.zeros((n_samples, 1))\n","\treturn X, y"]},{"cell_type":"markdown","metadata":{"id":"oAEKeMymnXpB"},"source":["#####Train Discriminator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zdL7o9xqnaYJ"},"outputs":[],"source":["# train the discriminator model\n","def train_discriminator(model, dataset, n_iter=100, n_batch=256):\n","\thalf_batch = int(n_batch / 2)\n","\t# manually enumerate epochs\n","\tfor i in range(n_iter):\n","\t\t# get randomly selected 'real' samples\n","\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n","\t\t# update discriminator on real samples\n","\t\t_, real_acc = model.train_on_batch(X_real, y_real)\n","\t\t# generate 'fake' examples\n","\t\tX_fake, y_fake = generate_fake_samples(half_batch)\n","\t\t# update discriminator on fake samples\n","\t\t_, fake_acc = model.train_on_batch(X_fake, y_fake)\n","\t\t# summarize performance\n","\t\tprint('>%d real=%.0f%% fake=%.0f%%' % (i+1, real_acc*100, fake_acc*100))"]},{"cell_type":"markdown","metadata":{"id":"0iRjbDpUkCG2"},"source":["####Generator\n","\n","\"LeakyReLU with a default slope of 0.2, reported as a best practice when training GAN models.\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8n1NyQqHv2ZH"},"outputs":[],"source":["# define the standalone generator model\n","def define_generator(latent_dim):\n","  model = Sequential()\n","  # foundation for 7x7 image\n","  n_nodes = 64 * 5 * 5\n","  model.add(Dense(n_nodes, input_dim=15))\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(Reshape((5, 5, 64)))\n","  # Upsample\n","  model.add(UpSampling2D())\n","  model.add(Conv2D(64, (3,3), padding='same'))\n","  model.add(LeakyReLU(alpha=0.2))\n","  # Upsample\n","  model.add(Conv2DTranspose(64, (3,3), strides=(2,2), padding='same'))\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(UpSampling2D())\n","  # Upsample\n","  model.add(Conv2DTranspose(64, (8,8), strides=(3,3)))\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(Conv2DTranspose(2, (5,5), strides=(4,1)))\n","\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"bS3oP57OvweR"},"source":["####Latent Space Operations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CZdfxqxTuYTe"},"outputs":[],"source":["# define the size of the latent space\n","latent_dim = 15\n","# define the generator model\n","model = define_generator(latent_dim)\n","# summarize the model\n","model.summary()\n","# plot the model\n","plot_model(model, to_file='generator_plot.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dPNbHUwHvyzl"},"outputs":[],"source":["# generate points in latent space as input for the generator\n","def generate_latent_points(latent_dim, n_samples):\n","\t# generate points in the latent space\n","\tx_input = np.random.randn(latent_dim * n_samples)\n","\t# reshape into a batch of inputs for the network\n","\tx_input = x_input.reshape(n_samples, latent_dim)\n","\treturn x_input"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADobp1agwwjz"},"outputs":[],"source":["# size of the latent space\n","latent_dim = 15\n","# define the discriminator model\n","model = define_generator(latent_dim)\n","# generate samples\n","n_samples = 5\n","X, _ = generate_fake_samples(model, latent_dim, n_samples)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZWFNIeiCJmfJ"},"outputs":[],"source":["X_gen = recompose_spect(X[:, :, :, 0], X[:, :, :, 1]) # Turn into complex valued array"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XWHz0Cx0wmVV"},"outputs":[],"source":["# plot the generated samples\n","for i in range(n_samples):\n","  show_spectro(y['times'][0], y['freq'][0], X_gen[i])"]},{"cell_type":"markdown","metadata":{"id":"8eQ_ygWN7f4b"},"source":["No audible sound as all the values are too low."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jal3EBthxXU6"},"outputs":[],"source":["spectro_to_audio(X_gen[0])"]},{"cell_type":"markdown","metadata":{"id":"FyWtngbUzjd6"},"source":["###GAN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MNJsSHVGzwed"},"outputs":[],"source":["# define the combined generator and discriminator model, for updating the generator\n","def define_gan(g_model, d_model):\n","  # make weights in the discriminator not trainable\n","  d_model.trainable = False\n","  # connect them\n","  model = Sequential()\n","  # add generator\n","  model.add(g_model)\n","  # add the discriminator\n","  model.add(d_model)\n","  # compile model\n","  opt = Adam(lr=0.0002, beta_1=0.5)\n","  model.compile(loss='binary_crossentropy', optimizer=opt)\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jdzBBn-003Xx"},"outputs":[],"source":["# size of the latent space\n","latent_dim = 15\n","# create the discriminator\n","d_model = define_discriminator()\n","# create the generator\n","g_model = define_generator(latent_dim)\n","# create the gan\n","gan_model = define_gan(g_model, d_model)\n","# summarize gan model\n","gan_model.summary()\n","# plot gan model\n","plot_model(gan_model, to_file='gan_plot.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"markdown","metadata":{"id":"w7ZGUh4L1dvW"},"source":["####Train GAN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j-Wo03tE1afi"},"outputs":[],"source":["# train the composite model\n","def train_gan(gan_model, latent_dim, n_epochs=100, n_batch=256):\n","\t# manually enumerate epochs\n","\tfor i in range(n_epochs):\n","\t\t# prepare points in latent space as input for the generator\n","\t\tx_gan = generate_latent_points(latent_dim, n_batch)\n","\t\t# create inverted labels for the fake samples\n","\t\ty_gan = np.ones((n_batch, 1))\n","\t\t# update the generator via the discriminator's error\n","\t\tgan_model.train_on_batch(x_gan, y_gan)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AdvpPREs2aYR"},"outputs":[],"source":["# train the generator and discriminator\n","def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=50, n_batch=256):\n","  bat_per_epo = int(dataset.shape[0] / n_batch)\n","  half_batch = int(n_batch / 2)\n","  # manually enumerate epochs\n","  for i in range(n_epochs):\n","    # enumerate batches over the training set\n","    for j in range(bat_per_epo):\n","      # get randomly selected 'real' samples\n","      X_real, y_real = generate_real_samples(dataset, half_batch)\n","      # generate 'fake' examples\n","      X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","      # create training set for the discriminator\n","      X = np.vstack((X_real.reshape(128, 501, 129, 1), X_fake)) # Reshape because of dimension bug\n","      y = np.vstack((y_real, y_fake))\n","      # update discriminator model weights\n","      d_loss, _ = d_model.train_on_batch(X, y)\n","      # prepare points in latent space as input for the generator\n","      X_gan = generate_latent_points(latent_dim, n_batch)\n","      # create inverted labels for the fake samples\n","      y_gan = np.ones((n_batch, 1))\n","      # update the generator via the discriminator's error\n","      g_loss = gan_model.train_on_batch(X_gan, y_gan)\n","      # summarize loss on this batch\n","      print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n","\n","    # evaluate the model performance, sometimes\n","    if (i+1) % 10 == 0:\n","      summarize_performance(i, g_model, d_model, dataset, latent_dim)"]},{"cell_type":"markdown","metadata":{"id":"vfJYaWoc3itt"},"source":["####Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KM0VuUzx3ldm"},"outputs":[],"source":["# evaluate the discriminator, plot generated images, save generator model\n","def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n","  # prepare real samples\n","  X_real, y_real = generate_real_samples(dataset, n_samples)\n","  # evaluate discriminator on real examples\n","  _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n","  # prepare fake examples\n","  x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n","  # evaluate discriminator on fake examples\n","  _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n","  # summarize discriminator performance\n","  print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n","  # save plot\n","  save_plot(x_fake, epoch)\n","  # save the generator model tile file\n","  filename = 'generator_model_%03d.h5' % (epoch + 1)\n","  g_model.save(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3FhlU84l4lTP"},"outputs":[],"source":["# create and save a plot of generated images (reversed grayscale)\n","def save_plot(examples, epoch, n=10):\n","  # plot images\n","  for i in range(n * n):\n","    show_spectro(y['times'][0], y['freq'][0], examples[i, :, :, 0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zW6FwbH65YoH"},"outputs":[],"source":["# size of the latent space\n","latent_dim = 15\n","# create the discriminator\n","d_model = define_discriminator()\n","# create the generator\n","g_model = define_generator(latent_dim)\n","# create the gan\n","gan_model = define_gan(g_model, d_model)\n","# load image data\n","dataset = np.array([y_real, y_imag]).reshape(1000, 501, 129, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hfe_Bncv7iQ7"},"outputs":[],"source":["# train model\n","train(g_model, d_model, gan_model, dataset, latent_dim)"]},{"cell_type":"markdown","metadata":{"id":"SF-5UXAUJ3W-"},"source":["####GAN Output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t8UqVueNyC6i"},"outputs":[],"source":["# load model\n","model = load_model('generator_model_0_020.h5')\n","# generate images\n","latent_points = generate_latent_points(15, 10)\n","# generate images\n","preds = model.predict(latent_points)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwW2aWTfyJLD"},"outputs":[],"source":["X_gen = recompose_spect(preds[:, :, :, 0], preds[:, :, :, 1]) # Turn into complex valued array\n","\n","# plot the generated samples\n","for i in range(X_gen.shape[0]):\n","  show_spectro(y['times'][0], y['freq'][0], X_gen[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VdHMNZTKy3Pw"},"outputs":[],"source":["spectro_to_audio(X_gen[0])"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["EOBY9t7Ombgr","u4-g2Jbdq1cd","iC5pMj03Q7Z7","yt6y_LQImozv"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
